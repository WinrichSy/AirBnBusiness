{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things I added:  \n",
    "pip install googletrans\n",
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run docker container\n",
    "sudo docker run -d --name sparkbook -p 8881:8888 -v \"$PWD\":/home/jovyan/work jupyter/pyspark-notebook start.sh jupyter lab --LabApp.token=''\n",
    "\n",
    "#Exec docker container\n",
    "docker exec -it sparkbook\n",
    "\n",
    "#Run Spark\n",
    "#go on browser\n",
    "localhost:8881"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run1\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run2\n",
    "import pyspark as ps\n",
    "\n",
    "spark = (ps.sql.SparkSession\n",
    "         .builder\n",
    "         .master('local[4]')\n",
    "         .appName('Instacart')\n",
    "         .getOrCreate()\n",
    "        )\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run5\n",
    "#Creates a text label above each bar in *rects*, displaying its height.\n",
    "def autolabel(rects, orientation='vert'):\n",
    "    #prints value above vertical bars\n",
    "    if orientation=='vert':\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{}'.format(int(height)),\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  # 3 points vertical offset\n",
    "                        weight = 'bold',\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom',\n",
    "                        size=15)\n",
    "    #Prints value to the right of horizontal bars\n",
    "    elif orientation=='hort':\n",
    "        for rect in rects:\n",
    "            width = rect.get_width()\n",
    "            ax.annotate('{}'.format(int(width)),\n",
    "                        xy=(width, rect.get_y() + rect.get_height() / 2),\n",
    "                        xytext=(3,-6),\n",
    "                        textcoords=\"offset points\",\n",
    "                        size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run6\n",
    "#Creates a text label above each bar in *rects*, displaying its height.\n",
    "def autolabel_percent(rects, orientation='vert'):\n",
    "    #Prints percentage above bars for vertical bars\n",
    "    if orientation=='vert':\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.annotate('{0:.2f}%'.format(height),\n",
    "                        xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                        xytext=(0, 3),  # 3 points vertical offset\n",
    "                        weight = 'bold',\n",
    "                        textcoords=\"offset points\",\n",
    "                        ha='center', va='bottom',\n",
    "                        size=15)\n",
    "    #Prints percentages to the right of bars in horizontal bars\n",
    "    elif orientation=='hort':\n",
    "        for rect in rects:\n",
    "            width = rect.get_width()\n",
    "            ax.annotate(\"{0:.2f}%\".format(width),\n",
    "                        xy=(width, rect.get_y() + rect.get_height() / 2),\n",
    "                        xytext=(3,-6),\n",
    "                        textcoords=\"offset points\",\n",
    "                        size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run7\n",
    "#Print functions for bar graphs specifically\n",
    "def print_bar(x, y, title, x_label, y_label, title='insert title', orientation='vert', color='blue', \n",
    "              width=0.65, fig_size=(23,7), percentage=False, weight='bold', tick_size=20, title_size=30):\n",
    "    fig, ax = plt.subplots(figsize=fig_size)\n",
    "    \n",
    "    if orientation=='vert':\n",
    "        bars_for_annotation = ax.bar(x, y, color=color, align='center', width=width)\n",
    "    elif orientation=='hort':\n",
    "        bars_for_annotation = ax.barh(x, y, color=color, align='center')\n",
    "        \n",
    "    plt.xticks(size = 13, rotation=90)\n",
    "    plt.yticks(size = 15)\n",
    "    plt.xlabel(x_label, size=tick_size, color=color)\n",
    "    plt.ylabel(y_label, size=tick_size, color=color)\n",
    "    plt.title(title, fontsize=title_size, color=color)\n",
    "        \n",
    "    if percentage:\n",
    "        autolabel_percent(bars_for_annotation, orientation)\n",
    "    elif not percentage:\n",
    "        autolabel(bars_for_annotation, orientation)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: test for stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: preprocessing the data (uncomment later)\n",
    "useless_listing_columns = ['square_feet','country','listing_url','scrape_id','last_scraped','experiences_offered', 'license', \n",
    "                   'xl_picture_url','host_url','host_name','host_thumbnail_url','street','host_listings_count',\n",
    "                   'neighbourhood_group_cleansed','state','market', 'calendar_last_scraped','host_picture_url',\n",
    "                   'host_acceptance_rate', 'minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights',\n",
    "                   'maximum_maximum_nights', 'jurisdiction_names', 'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes',\n",
    "                   'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms','maximum_nights_avg_ntm',\n",
    "                   'has_availability','country_code','host_acceptance_rate','thumbnail_url','medium_url','weekly_price','monthly_price',\n",
    "                   'calendar_updated','is_business_travel_ready', 'interaction', 'interaction', 'house_rules']\n",
    "\n",
    "def preprocessing(path):\n",
    "    #load the LISTINGS csv\n",
    "    processed_listings_df = pd.read_csv(path+'listings.csv')\n",
    "    #drop useless columns\n",
    "    processed_listings_df.drop(columns = useless_listing_columns, inplace=True)\n",
    "    \n",
    "    #load the CALENDAR csv\n",
    "    processed_calendar_df = pd.read_csv(path+'calendar.csv')\n",
    "    #Convert date strings to datetime type\n",
    "    date_time = pd.Series([datetime.strptime(x, '%Y-%m-%d') for x in processed_calendar_df['date']])\n",
    "    processed_calendar_df['date'] = date_time\n",
    "    \n",
    "    #load the REVIEWS csv\n",
    "    processed_reviews_df = pd.read_csv(path+'reviews.csv')\n",
    "    #Drop useless columns. Id of review and the reviewer's name\n",
    "    processed_reviews_df.drop(columns=['id', 'reviewer_name'], inplace=True)\n",
    "\n",
    "    return processed_listings_df, processed_calendar_df, processed_reviews_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/winrichsy/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "#Load up listings\n",
    "paris_listings = pd.read_csv('Data/Paris/listings.csv', nrows=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop useless columns (Paris)\n",
    "useless_columns = ['square_feet','country','listing_url','scrape_id','last_scraped','experiences_offered', 'license', \n",
    "                   'xl_picture_url','host_url','host_name','host_thumbnail_url','street','host_listings_count',\n",
    "                   'neighbourhood_group_cleansed','state','market', 'calendar_last_scraped','host_picture_url',\n",
    "                   'host_acceptance_rate', 'minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights',\n",
    "                   'maximum_maximum_nights', 'jurisdiction_names', 'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes',\n",
    "                   'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms','maximum_nights_avg_ntm',\n",
    "                   'has_availability','country_code','host_acceptance_rate','thumbnail_url','medium_url','weekly_price','monthly_price',\n",
    "                   'calendar_updated','is_business_travel_ready', 'interaction', 'interaction', 'house_rules', 'experiences_offered']\n",
    "paris_listings_shortened = paris_listings.drop(columns = useless_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save new csv\n",
    "singapore = 'Data/Singapore/'\n",
    "london = 'Data/London/'\n",
    "paris = 'Data/Paris/'\n",
    "\n",
    "# paris_data_shortened.to_csv (paris+'shortened_listings.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run3\n",
    "paris_listings = spark.read.csv(paris +'shortened_listings.csv',\n",
    "                           header = True,\n",
    "                           sep = \",\",\n",
    "                           inferSchema = True)\n",
    "\n",
    "paris_calendar = spark.read.csv(paris+'shortened_calendar.csv',\n",
    "                            header = True,\n",
    "                            sep = \",\",\n",
    "                            inferSchema = True)\n",
    "\n",
    "paris_reviews = spark.read.csv(paris+'shortened_reviews.csv',\n",
    "                                     header = True,\n",
    "                                     sep = \",\",\n",
    "                                     inferSchema = True)\n",
    "\n",
    "#==========================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load up Calendar (Paris)\n",
    "paris_calendar = pd.read_csv(paris + 'calendar.csv', nrows=25000)\n",
    "\n",
    "#Convert date strings to datetime type\n",
    "date_time = pd.Series([datetime.strptime(x, '%Y-%m-%d') for x in paris_calendar['date']])\n",
    "paris_calendar['date'] = date_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load up Reviews (Paris)\n",
    "paris_reviews = pd.read_csv(paris + 'reviews.csv', nrows=25000)\n",
    "\n",
    "#Drop useless columns. Id of review and the reviewer's name\n",
    "paris_reviews.drop(columns=['id', 'reviewer_name'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#detect language of reviewers\n",
    "#https://pypi.org/project/langdetect/\n",
    "import langdetect as ld\n",
    "#remove the rows with blank comments\n",
    "paris_reviews = paris_reviews.loc[paris_reviews['comments'].notna()]\n",
    "# paris_reviews = paris_reviews.loc[paris_reviews['comments']!='.']\n",
    "paris_reviews = paris_reviews.loc[paris_reviews['comments'].str.len()>20]\n",
    "\n",
    "\n",
    "comment_language = pd.Series([ld.detect(x) for x in paris_reviews['comments']])\n",
    "paris_reviews['language'] = comment_language\n",
    "\n",
    "#CAN: explain removing comments with less than 10 letters. it also finds the comments with random symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paris_reviews.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pypi.org/project/langua/\n",
    "from langua import Predict\n",
    "p = Predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#https://pypi.org/project/langua/\n",
    "from langua import Predict\n",
    "p = Predict()\n",
    "\n",
    "#detect language of hosts\n",
    "#1. Get only the description that are not empty\n",
    "#2. Get descriptions that are more than 20, overstepping random symbols\n",
    "paris_listings_shortened = paris_listings_shortened.loc[paris_listings_shortened['description'].notna()]\n",
    "paris_listings_shortened = paris_listings_shortened.loc[paris_listings_shortened['description'].str.len()>20]\n",
    "\n",
    "listing_language = [p.get_lang(x) for x in paris_listings['description']]\n",
    "\n",
    "paris_listings_shortened['language'] = listing_language\n",
    "#DO NOT RUN AGAIN UNTIL THE END: TAKES FOREVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEAVE THIS COMMENTED\n",
    "# import pycountry\n",
    "#Tested to change ISO 639-1 codes into their actual names\n",
    "#listing_language = ['zh' if x=='zh-cn' or x=='zh-tw' else x for x in listing_language]\n",
    "\n",
    "# listing_language = pd.Series([languages.get(alpha2=ld.detect(x)).name for x in listing_language[:10]])\n",
    "# listing_language\n",
    "\n",
    "# listing_language = pd.Series([pycountry.languages.get(alpha_2=ld.detect(x)).name for x in listing_language[:10]])\n",
    "# listing_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('say \"shit is done yo. get back to work\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_language.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pypi.org/project/iso-639/\n",
    "from iso639 import languages\n",
    "\n",
    "#Create dictionary on types of languages available\n",
    "keys = ['af', 'ar', 'bg', 'bn', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', \n",
    "        'es', 'et', 'fa', 'fi', 'fr', 'gu', 'he', 'hi', 'hr', 'hu', 'id', \n",
    "        'it', 'ja', 'kn', 'ko', 'lt', 'lv', 'mk', 'ml', 'mr', 'ne', 'nl', \n",
    "        'no', 'pa', 'pl', 'pt', 'ro', 'ru', 'sk', 'sl', 'so', 'sq', 'sv', \n",
    "        'sw', 'ta', 'te', 'th', 'tl', 'tr', 'uk', 'ur', 'vi', 'zh']\n",
    "\n",
    "#convert iso-639 to iso language name\n",
    "iso_name = [languages.get(alpha2=x).name for x in keys]\n",
    "\n",
    "language_dict = {}\n",
    "for idx, val in enumerate(keys):\n",
    "    language_dict[val] = iso_name[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
